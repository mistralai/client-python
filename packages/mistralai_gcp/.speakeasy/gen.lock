lockVersion: 2.0.0
id: ec60f2d8-7869-45c1-918e-773d41a8cf74
management:
  docChecksum: 05fc6f45406deac180ffc1df760c67f4
  docVersion: 1.0.0
  speakeasyVersion: 1.606.10
  generationVersion: 2.687.13
  releaseVersion: 2.0.0
  configChecksum: a1b03996b9a524c2110678cbe2b68226
  repoURL: https://github.com/mistralai/client-python.git
  repoSubDirectory: packages/mistralai_gcp
  installationURL: https://github.com/mistralai/client-python.git#subdirectory=packages/mistralai_gcp
  published: true
features:
  python:
    additionalDependencies: 1.0.0
    additionalProperties: 1.0.1
    constsAndDefaults: 1.0.5
    core: 5.20.1
    defaultEnabledRetries: 0.2.0
    enumUnions: 0.1.0
    envVarSecurityUsage: 0.3.2
    examples: 3.0.2
    flatRequests: 1.0.1
    globalSecurity: 3.0.3
    globalSecurityCallbacks: 1.0.0
    globalSecurityFlattening: 1.0.0
    globalServerURLs: 3.1.1
    methodArguments: 1.0.2
    nameOverrides: 3.0.1
    nullables: 1.0.1
    openEnums: 1.0.1
    responseFormat: 1.0.1
    retries: 3.0.2
    sdkHooks: 1.1.0
    serverEvents: 1.0.8
    serverEventsSentinels: 0.1.0
    serverIDs: 3.0.0
    unions: 3.0.4
generatedFiles:
  - .gitattributes
  - .vscode/settings.json
  - docs/models/arguments.md
  - docs/models/assistantmessage.md
  - docs/models/assistantmessagecontent.md
  - docs/models/assistantmessagerole.md
  - docs/models/chatcompletionchoice.md
  - docs/models/chatcompletionchoicefinishreason.md
  - docs/models/chatcompletionrequest.md
  - docs/models/chatcompletionrequestmessages.md
  - docs/models/chatcompletionrequeststop.md
  - docs/models/chatcompletionrequesttoolchoice.md
  - docs/models/chatcompletionresponse.md
  - docs/models/chatcompletionstreamrequest.md
  - docs/models/chatcompletionstreamrequesttoolchoice.md
  - docs/models/completionchunk.md
  - docs/models/completionevent.md
  - docs/models/completionresponsestreamchoice.md
  - docs/models/content.md
  - docs/models/contentchunk.md
  - docs/models/deltamessage.md
  - docs/models/fimcompletionrequest.md
  - docs/models/fimcompletionrequeststop.md
  - docs/models/fimcompletionresponse.md
  - docs/models/fimcompletionstreamrequest.md
  - docs/models/fimcompletionstreamrequeststop.md
  - docs/models/finishreason.md
  - docs/models/function.md
  - docs/models/functioncall.md
  - docs/models/functionname.md
  - docs/models/httpvalidationerror.md
  - docs/models/imageurl.md
  - docs/models/imageurlchunk.md
  - docs/models/imageurlchunkimageurl.md
  - docs/models/imageurlchunktype.md
  - docs/models/jsonschema.md
  - docs/models/loc.md
  - docs/models/messages.md
  - docs/models/mistralpromptmode.md
  - docs/models/prediction.md
  - docs/models/referencechunk.md
  - docs/models/referencechunktype.md
  - docs/models/responseformat.md
  - docs/models/responseformats.md
  - docs/models/role.md
  - docs/models/security.md
  - docs/models/stop.md
  - docs/models/systemmessage.md
  - docs/models/systemmessagecontent.md
  - docs/models/systemmessagecontentchunks.md
  - docs/models/textchunk.md
  - docs/models/thinkchunk.md
  - docs/models/thinkchunktype.md
  - docs/models/thinking.md
  - docs/models/tool.md
  - docs/models/toolcall.md
  - docs/models/toolchoice.md
  - docs/models/toolchoiceenum.md
  - docs/models/toolmessage.md
  - docs/models/toolmessagecontent.md
  - docs/models/toolmessagerole.md
  - docs/models/tooltypes.md
  - docs/models/type.md
  - docs/models/usageinfo.md
  - docs/models/usermessage.md
  - docs/models/usermessagecontent.md
  - docs/models/usermessagerole.md
  - docs/models/utils/retryconfig.md
  - docs/models/validationerror.md
  - poetry.toml
  - py.typed
  - pylintrc
  - pyproject.toml
  - scripts/prepare_readme.py
  - scripts/publish.sh
  - src/mistralai_gcp/__init__.py
  - src/mistralai_gcp/_hooks/__init__.py
  - src/mistralai_gcp/_hooks/sdkhooks.py
  - src/mistralai_gcp/_hooks/types.py
  - src/mistralai_gcp/_version.py
  - src/mistralai_gcp/basesdk.py
  - src/mistralai_gcp/chat.py
  - src/mistralai_gcp/fim.py
  - src/mistralai_gcp/httpclient.py
  - src/mistralai_gcp/models/__init__.py
  - src/mistralai_gcp/models/assistantmessage.py
  - src/mistralai_gcp/models/chatcompletionchoice.py
  - src/mistralai_gcp/models/chatcompletionrequest.py
  - src/mistralai_gcp/models/chatcompletionresponse.py
  - src/mistralai_gcp/models/chatcompletionstreamrequest.py
  - src/mistralai_gcp/models/completionchunk.py
  - src/mistralai_gcp/models/completionevent.py
  - src/mistralai_gcp/models/completionresponsestreamchoice.py
  - src/mistralai_gcp/models/contentchunk.py
  - src/mistralai_gcp/models/deltamessage.py
  - src/mistralai_gcp/models/fimcompletionrequest.py
  - src/mistralai_gcp/models/fimcompletionresponse.py
  - src/mistralai_gcp/models/fimcompletionstreamrequest.py
  - src/mistralai_gcp/models/function.py
  - src/mistralai_gcp/models/functioncall.py
  - src/mistralai_gcp/models/functionname.py
  - src/mistralai_gcp/models/httpvalidationerror.py
  - src/mistralai_gcp/models/imageurl.py
  - src/mistralai_gcp/models/imageurlchunk.py
  - src/mistralai_gcp/models/jsonschema.py
  - src/mistralai_gcp/models/mistralgcperror.py
  - src/mistralai_gcp/models/mistralpromptmode.py
  - src/mistralai_gcp/models/no_response_error.py
  - src/mistralai_gcp/models/prediction.py
  - src/mistralai_gcp/models/referencechunk.py
  - src/mistralai_gcp/models/responseformat.py
  - src/mistralai_gcp/models/responseformats.py
  - src/mistralai_gcp/models/responsevalidationerror.py
  - src/mistralai_gcp/models/sdkerror.py
  - src/mistralai_gcp/models/security.py
  - src/mistralai_gcp/models/systemmessage.py
  - src/mistralai_gcp/models/systemmessagecontentchunks.py
  - src/mistralai_gcp/models/textchunk.py
  - src/mistralai_gcp/models/thinkchunk.py
  - src/mistralai_gcp/models/tool.py
  - src/mistralai_gcp/models/toolcall.py
  - src/mistralai_gcp/models/toolchoice.py
  - src/mistralai_gcp/models/toolchoiceenum.py
  - src/mistralai_gcp/models/toolmessage.py
  - src/mistralai_gcp/models/tooltypes.py
  - src/mistralai_gcp/models/usageinfo.py
  - src/mistralai_gcp/models/usermessage.py
  - src/mistralai_gcp/models/validationerror.py
  - src/mistralai_gcp/py.typed
  - src/mistralai_gcp/sdkconfiguration.py
  - src/mistralai_gcp/types/__init__.py
  - src/mistralai_gcp/types/basemodel.py
  - src/mistralai_gcp/utils/__init__.py
  - src/mistralai_gcp/utils/annotations.py
  - src/mistralai_gcp/utils/datetimes.py
  - src/mistralai_gcp/utils/enums.py
  - src/mistralai_gcp/utils/eventstreaming.py
  - src/mistralai_gcp/utils/forms.py
  - src/mistralai_gcp/utils/headers.py
  - src/mistralai_gcp/utils/logger.py
  - src/mistralai_gcp/utils/metadata.py
  - src/mistralai_gcp/utils/queryparams.py
  - src/mistralai_gcp/utils/requestbodies.py
  - src/mistralai_gcp/utils/retries.py
  - src/mistralai_gcp/utils/security.py
  - src/mistralai_gcp/utils/serializers.py
  - src/mistralai_gcp/utils/unmarshal_json_response.py
  - src/mistralai_gcp/utils/url.py
  - src/mistralai_gcp/utils/values.py
examples:
  stream_chat:
    speakeasy-default-stream-chat:
      requestBody:
        application/json: {"model": "mistral-large-latest", "stream": true, "messages": [{"content": "Who is the best French painter? Answer in one short sentence.", "role": "user"}], "response_format": {"type": "text"}}
      responses:
        "422":
          application/json: {}
  chat_completion_v1_chat_completions_post:
    speakeasy-default-chat-completion-v1-chat-completions-post:
      requestBody:
        application/json: {"model": "mistral-large-latest", "stream": false, "messages": [{"content": "Who is the best French painter? Answer in one short sentence.", "role": "user"}], "response_format": {"type": "text"}}
      responses:
        "200":
          application/json: {"id": "cmpl-e5cc70bb28c444948073e77776eb30ef", "object": "chat.completion", "model": "mistral-small-latest", "usage": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}, "created": 1702256327, "choices": []}
        "422":
          application/json: {}
  stream_fim:
    speakeasy-default-stream-fim:
      requestBody:
        application/json: {"model": "codestral-latest", "top_p": 1, "stream": true, "prompt": "def", "suffix": "return a+b"}
      responses:
        "422":
          application/json: {}
  fim_completion_v1_fim_completions_post:
    userExample:
      requestBody:
        application/json: {"model": "codestral-latest", "top_p": 1, "stream": false, "prompt": "def", "suffix": "return a+b"}
      responses:
        "200":
          application/json: {"id": "447e3e0d457e42e98248b5d2ef52a2a3", "object": "chat.completion", "model": "codestral-2508", "usage": {"prompt_tokens": 8, "completion_tokens": 91, "total_tokens": 99}, "created": 1759496862, "choices": [{"index": 0, "message": {"content": "add_numbers(a: int, b: int) -> int:\n    \"\"\"\n    You are given two integers `a` and `b`. Your task is to write a function that\n    returns the sum of these two integers. The function should be implemented in a\n    way that it can handle very large integers (up to 10^18). As a reminder, your\n    code has to be in python\n    \"\"\"\n", "tool_calls": null, "prefix": false, "role": "assistant"}, "finish_reason": "stop"}]}
examplesVersion: 1.0.2
generatedTests: {}
releaseNotes: "## SDK Changes Detected:\n* `mistral_gcp.chat.complete()`: \n  *  `request` **Changed** **Breaking** :warning:\n  *  `response` **Changed**\n* `mistral_gcp.fim.complete()`:  `response` **Changed**\n"
